{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fded1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9c6894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hevas\\anaconda3\\envs\\educacion\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5028cb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "derivada: [8.0]\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "x_eval = 4\n",
    "def f(x):\n",
    "  return tf.math.square(x)\n",
    "##########################\n",
    "x = tf.placeholder(tf.float32,[])\n",
    "y = f(x)\n",
    "\n",
    "derivada = tf.gradients(f(x),[x])\n",
    "############################\n",
    "with tf.train.MonitoredSession() as session:\n",
    "  feed_dict = {x:x_eval}\n",
    "\n",
    "  valor_y,valor_derivada = session.run([y,derivada],feed_dict)\n",
    "  print(\"derivada:\",valor_derivada)\n",
    "  print(valor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a71fe899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(m,b,x):\n",
    "  \"\"\"Modelo/hipotesis\"\"\"\n",
    "  y = m*x + b\n",
    "\n",
    "  return y\n",
    "\n",
    "def costo(y_real,y_aprox):\n",
    "  \"\"\"Funcion de costo/perdida/error\n",
    "    para este caso: mean squared error(MSE)\n",
    "  \"\"\"\n",
    "  return 1/2*tf.reduce_mean(tf.math.square(y_real - y_aprox) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f5fdbe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in method TFE_Py_TapeWatch of PyCapsule object at 0x000002AFA30BA600> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'RefVariable' object has no attribute '_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     14\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m grad_tape:\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mgrad_tape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     grad_tape\u001b[38;5;241m.\u001b[39mwatch(m)\n\u001b[0;32m     18\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m h(m,b,x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\educacion\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:919\u001b[0m, in \u001b[0;36mGradientTape.watch\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    917\u001b[0m   tape\u001b[38;5;241m.\u001b[39mwatch_variable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape, t)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 919\u001b[0m   \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\educacion\\lib\\site-packages\\tensorflow\\python\\eager\\tape.py:56\u001b[0m, in \u001b[0;36mwatch\u001b[1;34m(tape, tensor)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwatch\u001b[39m(tape, tensor):\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;124;03m\"\"\"Marks this tensor to be watched by the given tape.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m   \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeWatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSystemError\u001b[0m: <built-in method TFE_Py_TapeWatch of PyCapsule object at 0x000002AFA30BA600> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "########### hyper-parametros\n",
    "lr = 0.001\n",
    "epochs = 30\n",
    "########### \n",
    "\n",
    "########### parametros entrenables\n",
    "m = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "###########\n",
    "\n",
    "errores = [] # almacenara el error de cada iteracion\n",
    "\n",
    "for i in range(epochs):\n",
    "  with tf.GradientTape() as grad_tape:\n",
    "    grad_tape.watch(b)\n",
    "    grad_tape.watch(m)\n",
    "\n",
    "    y_pred = h(m,b,x)\n",
    "    error = costo(y,y_pred)\n",
    "\n",
    "  # calcular el gradiente de la funcion de costo respecto de los parametros\n",
    "  grad_m,grad_b = grad_tape.gradient(error,[m,b])\n",
    "\n",
    "  # actualizar los parametros dando un paso en direccion contraria al gradiente\n",
    "  m.assign(m - lr*grad_m)\n",
    "  b.assign(b - lr*grad_b)\n",
    "\n",
    "  # almacenar o procesar cualquier informacion relevante\n",
    "  errores.append(error.numpy())\n",
    "  \n",
    "  \n",
    "  print(\"Iteracion {}, error:{}\".format(i,error))\n",
    "  print(\"    modelo:y={}x+{}\".format(m.numpy(),b.numpy()))\n",
    "\n",
    "print(\"Modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb41ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
